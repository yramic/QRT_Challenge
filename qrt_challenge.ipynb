{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Return Prediction Challenge by QRT\n",
    "\n",
    "    I) Data Exploration and Understanding:\n",
    "        1)  Load and inspect data\n",
    "        2)  Visualize distributions\n",
    "        3)  Correlation Analysis\n",
    "\n",
    "    II) Handle Missing Values\n",
    "        -   Usage of interpolation methods which makes sense for time series data.\n",
    "        -   Forward-fill or backward-fill missing values if temporal order is assumed\n",
    "        -   If no temporal continuity, then statistics like mean, median or conditiona averages\n",
    "\n",
    "    III) Noise and Outlier Handling\n",
    "        -   Robust statistics like the median\n",
    "\n",
    "    IV) Feature Engineering\n",
    "        1)  Feature Selection: Start with a feature selection and add features to see\n",
    "            changes in predictive power. Can be used as some sort of abliation study.\n",
    "        2)  Lagged Features: Compute rolling statistics (mean, std) for RET_1 to RET_20 and Volumes \n",
    "            over various windows\n",
    "        3)  Interaction Terms: Create features that combine stock-specific and sector-specific trends.\n",
    "        4)  If dates are randomized no extraction of temporal patterns is possible. Then focus on \n",
    "            relationships instead.\n",
    "        5) Maybe use Log or Fourier Transforms and Features:\n",
    "            -   Log Transform: To stabilize vairance and handle skewed data.    \n",
    "                Works on individual features. Can reduce impact of outliers.\n",
    "            -   Fourier Features: Captures periodic / seasonal patterns. \n",
    "                Requires sequential data (time-series). Can filter noise with low frequencies.\n",
    "        6) Feature Selection through Feature Importance\n",
    "\n",
    "    V) Models and Benchmark:\n",
    "        1)  Start simple with the Baseline Random Forest Implementation and  \n",
    "            cross validation to ensure proper assessment and avoid overfitting\n",
    "        2)  Tryout of SOTA models such as CatBoost or AutoGluon by Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Necessary Libraries\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "from model.ml_model import ModelTrainer\n",
    "from features.feature_engineering import generate_features\n",
    "\n",
    "DATASET_PATH = 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'data'\n",
    "\n",
    "# Load the relevant datasets\n",
    "x_train = pd.read_csv(os.path.join(DATASET_PATH, 'x_train.csv'))\n",
    "y_train = pd.read_csv(os.path.join(DATASET_PATH, 'y_train.csv'))\n",
    "\n",
    "test_df = pd.read_csv(os.path.join(DATASET_PATH, 'x_test.csv'))\n",
    "train_df = pd.concat((x_train, y_train), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data with NaN Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_features = [f'RET_{day}' for day in range(1,21)]\n",
    "rows_to_drop = train_df[\n",
    "    (train_df[return_features].isna().sum(axis=1) == len(return_features))\n",
    "]\n",
    "rows_to_drop\n",
    "# It becomes clear that we want to delete all rows where for every single day NaN \n",
    "# is recorded since we can't interpolate or replace those values.\n",
    "train_df.drop(index=rows_to_drop.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for inbalances\n",
    "A detailed analysis of the dataset distribution was conducted to determine whether most of the data follows a specific statistical pattern. Additionally, a statistical examination can provide insights into whether introducing new features would be beneficial. If a clear skew is detected, applying transformations such as logarithmic features can help improve the model's performance. Also to compute these the folder features, in particular statistical_features.py offers a more indepth analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df['RET'].value_counts(normalize=True)*100)\n",
    "# From this result it can be seen that there are no inbalances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling of further NaN Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in range(1, 21):\n",
    "    # Replace missing VOLUME features\n",
    "    train_df[f'VOLUME_{day}'] = train_df[f'VOLUME_{day}'].fillna(train_df[f'VOLUME_{day}'].median())\n",
    "    test_df[f'VOLUME_{day}'] = test_df[f'VOLUME_{day}'].fillna(test_df[f'VOLUME_{day}'].median())\n",
    "    \n",
    "    # Replace missing RET features\n",
    "    train_df[f'RET_{day}'] = train_df[f'RET_{day}'].fillna(train_df[f'RET_{day}'].median())\n",
    "    test_df[f'RET_{day}'] = test_df[f'RET_{day}'].fillna(test_df[f'RET_{day}'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Domain Specific Features \n",
    "These specific features can be found in the folder features. Where they are classified as Return Rate specific or Volume specific features. These features are commonly known signals used for portfolio management.\n",
    "\n",
    "#### Return-Related Features:\n",
    "\n",
    "    1. Autocorrelation of Returns (ACF)\n",
    "    2. Rolling Sharpe Ratio\n",
    "    3. Relative Strength Index (RSI)\n",
    "    4. Rate of Change (ROC)\n",
    "    5. Momentum\n",
    "    6. Stochastic Oscillator\n",
    "    7. Moving Average Convergence Divergence (MACD)\n",
    "    8. Golden Cross\n",
    "    9. Bollinger Bands\n",
    "    10. Cumulative Return\n",
    "    11. Money Flow Index (MFI)\n",
    "    12. Average True Range (ATR)\n",
    "    13. Lagged Returns (Multiple Lags)\n",
    "\n",
    "\n",
    "#### Volume-Related Features:\n",
    "\n",
    "    1. Volume Price Trend (VPT)\n",
    "    2. On-Balance Volume (OBV)\n",
    "    3. Chaikin Money Flow (CMF)\n",
    "    4. Volume Weighted Average Price (VWAP)\n",
    "    5. Volume Oscillator\n",
    "    6. Moving Average Convergence Divergence (MACD) here on Volume\n",
    "    7. Volume Change Ratio (VCR)\n",
    "    8. Price-Volume-Trend (PVT)\n",
    "    9. Average Volume (for the last 'n' days)\n",
    "    10. Volume Deviation\n",
    "    11. Volume Spike Detection\n",
    "    12. Accumulation/Distribution Line (ADL)\n",
    "    13. Relative Volume\n",
    "\n",
    "#### Cross / Statistical Features:\n",
    "\n",
    "    1. Return x Volume Interaction\n",
    "    2. Lagged Return x Volume Interaction\n",
    "    3. Cumulative Return - Volume Interaction\n",
    "    4. Sector or Industry-Specific Trends\n",
    "\n",
    "This is a rather extensive list that captures essential features for the return and volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, new_features = generate_features(train_df, test_df)\n",
    "\n",
    "# Further preparation to start training\n",
    "target = 'RET'\n",
    "original_features = list(x_train.keys())\n",
    "\n",
    "remove_features = ['DATE', 'ID', 'STOCK', 'INDUSTRY', 'INDUSTRY_GROUP', 'SECTOR', 'SUB_INDUSTRY']\n",
    "\n",
    "for feature in remove_features:\n",
    "    original_features = list(filter(lambda x: x != feature, original_features))\n",
    "\n",
    "features = new_features + original_features\n",
    "print(f'Number of Features used for Prediction and Training: {len(features)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for Training\n",
    "\n",
    "here you can choose whether to train a model or activate cross validation analyze its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = train_df[features]\n",
    "Y_train = train_df[target]\n",
    "\n",
    "X_test = test_df[features]\n",
    "\n",
    "use_model = 'CatBoost'\n",
    "cross_validation = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection and Training\n",
    "\n",
    "I tried out the following models:\n",
    "1. CatBoost\n",
    "2. RandomForest\n",
    "3. AutoGluon\n",
    "4. TabPFN\n",
    "5. XGBoost\n",
    "6. Ensembles\n",
    "\n",
    "TabPFN is state of the art and a tabular foundation model was even presented just recently in the year 2025. The issue is that it can only handle small tabular datasets with less than 10k rows. In the [TabPFN](https://www.nature.com/articles/s41586-024-08328-6) paper, the authors mentioned that for large datasets and roughly a 100 features the best performing model turned out to be always AutoGluon. In my case I received bad results but this is most likely due to a bad choice of hyperparameter. Furthermore the model requires a lot of compute thus I ran it on the cluster. With a better hyperparameter strategy and more training I am confident that better results could have been achieved. In the End I used the result from CatBoost but also here through better hyperparameter tuning to avoid overfitting, better results could have been achieved. Eventhough in theory AutoGluon should already build ensembles, I tried to combine CatBoost, RandomForest and XGBoost as a manual ensemble with equal weighting.\n",
    "\n",
    "$$\n",
    "Ensemble(X) = \\lambda_1 \\cdot CatBoost(X) + \\lambda_2 \\cdot RandomForest(X) + \\lambda_3 \\cdot XGBoost(X)\n",
    "$$\n",
    "\n",
    "X is here the input and each component describes the predicted output which is computed through this weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if use_model == 'RandomForest':\n",
    "    rf_params = {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 2**3,\n",
    "        'random_state': 0,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    model = RandomForestClassifier(**rf_params)\n",
    "    rf_model = ModelTrainer(model=RandomForestClassifier(**rf_params))\n",
    "\n",
    "elif use_model == 'CatBoost':\n",
    "    cat_params = {\n",
    "        'iterations': 2000,\n",
    "        'depth': 8,\n",
    "        'learning_rate': 0.05,\n",
    "        'loss_function': 'Logloss',\n",
    "        'verbose': False\n",
    "    }\n",
    "\n",
    "    model = CatBoostClassifier(**cat_params)\n",
    "    cat_model = ModelTrainer(model=CatBoostClassifier(**cat_params))\n",
    "\n",
    "elif use_model == 'XGBoost':\n",
    "    xg_params = {\n",
    "        'n_estimators': 10, \n",
    "        'max_depth': 8,          \n",
    "        'learning_rate': 0.05,  \n",
    "        'subsample': 0.8,      \n",
    "        'colsample_bytree': 0.8,   \n",
    "        'objective': 'binary:logistic', \n",
    "        'eval_metric': 'logloss',   \n",
    "        'random_state': 0,\n",
    "        'n_jobs': -1,       \n",
    "        'tree_method': 'hist'  \n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**xg_params)\n",
    "\n",
    "elif use_model == 'AutoGluon':\n",
    "    monster_params = {'label': target}\n",
    "    model = TabularPredictor(**monster_params)\n",
    "\n",
    "else:\n",
    "    raise ValueError('Not a valid model!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training / Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_model = ModelTrainer(model=model, use_model=use_model)\n",
    "\n",
    "if cross_validation:\n",
    "    if use_model == 'AutoGluon':\n",
    "        ml_model.validate_model(\n",
    "            X=X_train, \n",
    "            Y=Y_train, \n",
    "            time_limit=3600, \n",
    "            num_gpus=1, \n",
    "            num_cpus=1\n",
    "        )\n",
    "    else:\n",
    "        ml_model.cross_validate(X=X_train, Y=Y_train)\n",
    "\n",
    "else:\n",
    "    if use_model == 'AutoGluon':\n",
    "        X_train = pd.concat((X_train, Y_train), axis=1)\n",
    "        ml_model.model.fit(\n",
    "            train_data=X_train,\n",
    "            time_limit=100, \n",
    "            verbosity=3,\n",
    "            num_gpus=1,\n",
    "            num_cpus=1\n",
    "        )\n",
    "    else:\n",
    "        ml_model.model.fit(X_train, Y_train)\n",
    "\n",
    "    prediction = ml_model.predict(X_test)\n",
    "    ml_model.save_submission(pred=prediction, test_set=test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
